{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee11b763",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065c3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117e1d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models.from_config import build_from_config\n",
    "from models.double_branch import DoubleBranchCNN\n",
    "from data_handlers.csv_dataset import CustomDatasetFromDataFrame\n",
    "from utils import utils\n",
    "from utils import transfer_learning as tl\n",
    "from train import train, dual_train\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77550fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH=os.path.join('data','final_dataset.csv')\n",
    "DATA_DIR=os.path.join('data','landsat_7','')\n",
    "FOLD_PATH=os.path.join('data','dhs_incountry_folds.pkl')\n",
    "CONFIG_FILE_MS = os.path.join('configs','resnet18_ms_e2e_l7_yeh.json')\n",
    "CONFIG_FILE_MSNL = os.path.join('configs','resnet18_msnl_e2e_l7_yeh.json')\n",
    "TILE_MIN = [-0.0994, -0.0574, -0.0318, -0.0209, -0.0102, -0.0152, 0.0, -0.07087274]\n",
    "TILE_MAX = [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 316.7, 3104.1401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5da8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>households</th>\n",
       "      <th>wealthpooled</th>\n",
       "      <th>geometry</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.350257</td>\n",
       "      <td>13.534922</td>\n",
       "      <td>36</td>\n",
       "      <td>2.312757</td>\n",
       "      <td>POINT (1506700.58557273 -1385596.0684884773)</td>\n",
       "      <td>angola_2011_1_23127.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.360865</td>\n",
       "      <td>13.551494</td>\n",
       "      <td>32</td>\n",
       "      <td>2.010293</td>\n",
       "      <td>POINT (1508545.372017885 -1386804.9130245172)</td>\n",
       "      <td>angola_2011_2_20102.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>-12.613421</td>\n",
       "      <td>13.413085</td>\n",
       "      <td>36</td>\n",
       "      <td>0.877744</td>\n",
       "      <td>POINT (1493137.790366379 -1415600.6075743325)</td>\n",
       "      <td>angola_2011_3_08777.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>-12.581454</td>\n",
       "      <td>13.397711</td>\n",
       "      <td>35</td>\n",
       "      <td>1.066994</td>\n",
       "      <td>POINT (1491426.3440705661 -1411954.2588894619)</td>\n",
       "      <td>angola_2011_4_10669.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>-12.578135</td>\n",
       "      <td>13.418748</td>\n",
       "      <td>37</td>\n",
       "      <td>1.750153</td>\n",
       "      <td>POINT (1493768.1835246533 -1411575.617279712)</td>\n",
       "      <td>angola_2011_5_17501.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year  cluster        lat        lon  households  wealthpooled  \\\n",
       "0  angola  2011        1 -12.350257  13.534922          36      2.312757   \n",
       "1  angola  2011        2 -12.360865  13.551494          32      2.010293   \n",
       "2  angola  2011        3 -12.613421  13.413085          36      0.877744   \n",
       "3  angola  2011        4 -12.581454  13.397711          35      1.066994   \n",
       "4  angola  2011        5 -12.578135  13.418748          37      1.750153   \n",
       "\n",
       "                                         geometry                 filename  \n",
       "0    POINT (1506700.58557273 -1385596.0684884773)  angola_2011_1_23127.tif  \n",
       "1   POINT (1508545.372017885 -1386804.9130245172)  angola_2011_2_20102.tif  \n",
       "2   POINT (1493137.790366379 -1415600.6075743325)  angola_2011_3_08777.tif  \n",
       "3  POINT (1491426.3440705661 -1411954.2588894619)  angola_2011_4_10669.tif  \n",
       "4   POINT (1493768.1835246533 -1411575.617279712)  angola_2011_5_17501.tif  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open( CONFIG_FILE_MS ) as f:\n",
    "    config_ms = json.load(f)\n",
    "with open( CONFIG_FILE_MSNL ) as f:\n",
    "    config_msnl = json.load(f)\n",
    "csv = pd.read_csv(CSV_PATH)\n",
    "# csv['filename']=csv.apply(\n",
    "#     lambda row:  str(row['lat'])[:5].replace('.','_')+\"_\"+str(row.lon)[:5].replace('.','_')+'.tif', axis=1\n",
    "# )\n",
    "csv.drop(\"bounding_box\", axis=1, inplace=True)\n",
    "csv = csv.loc[:, ~csv.columns.str.contains('^Unnamed')]\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adfeb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TRANSFORM = torch.nn.Sequential(\n",
    "        torchvision.transforms.CenterCrop(size=224),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=torch.tensor([0.0761, 0.0722, 0.0687, 0.1369, 0.1298, 0.0933, 0.9453, 0.0017]),\n",
    "            std=torch.tensor([0.0119, 0.0171, 0.0277, 0.0304, 0.0476, 0.0443, 0.0193, 0.0073])\n",
    "        )\n",
    "    )\n",
    "TEST_TRANSFORM  = torch.nn.Sequential(\n",
    "        torchvision.transforms.CenterCrop(size=224),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28af04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE THE MEAN AND STD OF NORMED IMAGES OVER THE COMPLETE DATASET\n",
    "\n",
    "dummy_dataset = CustomDatasetFromDataFrame(csv,\n",
    "                                           DATA_DIR,\n",
    "                                           transform=TEST_TRANSFORM,\n",
    "                                           tile_max=TILE_MAX,\n",
    "                                           tile_min=TILE_MIN)\n",
    "dummy_loader = torch.utils.data.DataLoader(\n",
    "        dummy_dataset, \n",
    "        batch_size=64\n",
    "    )\n",
    "\n",
    "def compute_mean_and_std(dataloader, batch_size):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        if data is not None:\n",
    "            weight = data.size()[0] / batch_size\n",
    "            # Mean over batch, height and width, but not over the channels\n",
    "            channels_sum += weight*torch.mean(data, dim=[0,2,3])\n",
    "            channels_squared_sum += weight*torch.mean(data**2, dim=[0,2,3])\n",
    "            num_batches += weight\n",
    "    mean = channels_sum / num_batches\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "    return mean, std\n",
    "\n",
    "means, stds = compute_mean_and_std(dummy_loader, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a375ed2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0761, 0.0722, 0.0687, 0.1369, 0.1298, 0.0933, 0.9453, 0.0017]),\n",
       " tensor([0.0119, 0.0171, 0.0277, 0.0304, 0.0476, 0.0443, 0.0193, 0.0073]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20462eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold A\n"
     ]
    }
   ],
   "source": [
    "# Spatially Aware Cross-Validation\n",
    "with open(FOLD_PATH, 'rb') as f:\n",
    "    folds = pickle.load(f)\n",
    "results = dict()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for fold in folds:\n",
    "    writer = SummaryWriter()\n",
    "    r2 = torchmetrics.R2Score().to(device=device)\n",
    "    # Index split\n",
    "    train_split = folds[fold]['train']\n",
    "    val_split = folds[fold]['val']\n",
    "    test_split = folds[fold]['test']\n",
    "    # CSV split\n",
    "    train_df = csv.iloc[train_split]\n",
    "    val_df = csv.iloc[train_split]\n",
    "    test_df = csv.iloc[test_split]\n",
    "    # Datasets\n",
    "    train_dataset = CustomDatasetFromDataFrame(train_df, DATA_DIR,transform=TRAIN_TRANSFORM,tile_max=TILE_MAX,\n",
    "                                           tile_min=TILE_MIN )\n",
    "    val_dataset = CustomDatasetFromDataFrame(val_df, DATA_DIR, transform=TEST_TRANSFORM,tile_max=TILE_MAX,\n",
    "                                           tile_min=TILE_MIN )\n",
    "    test_dataset  = CustomDatasetFromDataFrame(test_df, DATA_DIR, transform=TEST_TRANSFORM,tile_max=TILE_MAX,\n",
    "                                           tile_min=TILE_MIN)\n",
    "    # DataLoaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config_ms['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config_ms['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config_ms['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    base_model = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "    # base_model = torchgeo.models.resnet18(weights=torchgeo.models.ResNet18_Weights.SENTINEL2_ALL_MOCO)\n",
    "    ms_branch = build_from_config( base_model=base_model, config_file=CONFIG_FILE_MS )\n",
    "    # nl_branch = tl.update_single_layer(torchvision.models.resnet18())\n",
    "    # model = DoubleBranchCNN(b1=ms_branch, b2=nl_branch, output_features=1)\n",
    "    model = ms_branch.to(device=device)\n",
    "    # CONFIGURE LOSS, OPTIM\n",
    "    loss_fn = utils.configure_loss( config_ms )\n",
    "    optimizer = utils.configure_optimizer( config_ms, model )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer)\n",
    "    print(f\"Training on fold {fold}\")\n",
    "    results[fold] = train(\n",
    "        model=model,\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=config_ms['n_epochs'],\n",
    "        batch_size=config_ms['batch_size'],\n",
    "        in_channels=config_ms['in_channels'],\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        r2=r2\n",
    "    )\n",
    "    torch.save(model.state_dict(), config_ms['checkpoint_path']+'_fold_'+str(fold)+\".pth\")\n",
    "final_results = utils.compute_average_crossval_results(results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e37d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dabce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatially Aware Cross-Validation\n",
    "with open(FOLD_PATH, 'rb') as f:\n",
    "    folds = pickle.load(f)\n",
    "results = dict()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for fold in folds:\n",
    "    writer = SummaryWriter()\n",
    "    r2 = torchmetrics.R2Score().to(device=device)\n",
    "    # Index split\n",
    "    train_split = folds[fold]['train']\n",
    "    val_split = folds[fold]['val']\n",
    "    test_split = folds[fold]['test']\n",
    "    # CSV split\n",
    "    train_df = csv.iloc[train_split]\n",
    "    val_df = csv.iloc[train_split]\n",
    "    test_df = csv.iloc[test_split]\n",
    "    # Datasets\n",
    "    train_dataset = CustomDatasetFromDataFrame(train_df, DATA_DIR,transform=TRAIN_TRANSFORM )\n",
    "    val_dataset = CustomDatasetFromDataFrame(val_df, DATA_DIR, transform=TEST_TRANSFORM )\n",
    "    test_dataset  = CustomDatasetFromDataFrame(test_df, DATA_DIR, transform=TEST_TRANSFORM )\n",
    "    # DataLoaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config_msnl['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config_msnl['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config_msnl['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    base_model = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "    # base_model = torchgeo.models.resnet18(weights=torchgeo.models.ResNet18_Weights.SENTINEL2_ALL_MOCO)\n",
    "    ms_branch = build_from_config( base_model=base_model, config_file=CONFIG_FILE_MSNL )\n",
    "    nl_branch = tl.update_single_layer(torchvision.models.resnet18())\n",
    "    model = DoubleBranchCNN(b1=ms_branch, b2=nl_branch, output_features=1)\n",
    "    model = model.to(device=device)\n",
    "    # CONFIGURE LOSS, OPTIM\n",
    "    loss_fn = utils.configure_loss( config_msnl )\n",
    "    optimizer = utils.configure_optimizer( config_msnl, model )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer)\n",
    "    print(f\"Training on fold {fold}\")\n",
    "    results[fold] = dual_train(\n",
    "        model=model,\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=config_msnl['n_epochs'],\n",
    "        batch_size=config_msnl['batch_size'],\n",
    "        in_channels=config_msnl['in_channels'],\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        r2=r2\n",
    "    )\n",
    "    torch.save(model.state_dict(), config_msnl['checkpoint_path']+'_fold_'+str(fold)+\".pth\")\n",
    "final_results_nl = utils.compute_average_crossval_results(results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f428df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b5e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac9b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccb8ae5a",
   "metadata": {},
   "source": [
    "3. Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db74dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_r2, Y_true, Y_pred = test(model=model, dataloader=val_loader, device=device)\n",
    "# # Y_true = [ utils.denormalize_asset(asset) for asset in Y_true]\n",
    "# # Y_pred = [ utils.denormalize_asset(asset) for asset in Y_pred]\n",
    "# results = pd.DataFrame({\n",
    "#     'true index':np.array(Y_true),\n",
    "#     'predicted index':np.array(Y_pred)\n",
    "# })\n",
    "# from scipy.stats import pearsonr\n",
    "# import seaborn as sns\n",
    "# sns.set_palette(\"rocket\")\n",
    "# sns.regplot(x='true index', y='predicted index', data=results).set(title='R2 = '+str(test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68768d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01ed5c42258d104453582e2fee2faf5d01150c2a161fd6cc7123c0fdfe444c60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
