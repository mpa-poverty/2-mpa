{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee11b763",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "065c3f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117e1d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchinfo\n",
    "import torch \n",
    "import torchmetrics\n",
    "import torchgeo.models\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from models.from_config import build_from_config\n",
    "from data_handlers.csv_dataset import CustomDatasetFromDataFrame\n",
    "from utils import utils\n",
    "from train import train\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e77550fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH=os.path.join('data','geometry_less_dataset.csv')\n",
    "DATA_DIR=os.path.join('data','landsat_tif','')\n",
    "FOLD_PATH=os.path.join('data','dhs_incountry_folds.pkl')\n",
    "CONFIG_FILE = os.path.join('configs','resnet18_ms_e2e_l7_1e2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5da8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>households</th>\n",
       "      <th>wealthpooled</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.350257</td>\n",
       "      <td>13.534922</td>\n",
       "      <td>36</td>\n",
       "      <td>2.312757</td>\n",
       "      <td>-12_3_13_53.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.360865</td>\n",
       "      <td>13.551494</td>\n",
       "      <td>32</td>\n",
       "      <td>2.010293</td>\n",
       "      <td>-12_3_13_55.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>-12.613421</td>\n",
       "      <td>13.413085</td>\n",
       "      <td>36</td>\n",
       "      <td>0.877744</td>\n",
       "      <td>-12_6_13_41.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>-12.581454</td>\n",
       "      <td>13.397711</td>\n",
       "      <td>35</td>\n",
       "      <td>1.066994</td>\n",
       "      <td>-12_5_13_39.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>-12.578135</td>\n",
       "      <td>13.418748</td>\n",
       "      <td>37</td>\n",
       "      <td>1.750153</td>\n",
       "      <td>-12_5_13_41.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year  cluster        lat        lon  households  wealthpooled  \\\n",
       "0  angola  2011        1 -12.350257  13.534922          36      2.312757   \n",
       "1  angola  2011        2 -12.360865  13.551494          32      2.010293   \n",
       "2  angola  2011        3 -12.613421  13.413085          36      0.877744   \n",
       "3  angola  2011        4 -12.581454  13.397711          35      1.066994   \n",
       "4  angola  2011        5 -12.578135  13.418748          37      1.750153   \n",
       "\n",
       "          filename  \n",
       "0  -12_3_13_53.tif  \n",
       "1  -12_3_13_55.tif  \n",
       "2  -12_6_13_41.tif  \n",
       "3  -12_5_13_39.tif  \n",
       "4  -12_5_13_41.tif  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open( CONFIG_FILE ) as f:\n",
    "    config = json.load(f)\n",
    "csv = pd.read_csv(CSV_PATH)\n",
    "csv['filename']=csv.apply(\n",
    "    lambda row:  str(row['lat'])[:5].replace('.','_')+\"_\"+str(row.lon)[:5].replace('.','_')+'.tif', axis=1\n",
    ")\n",
    "csv = csv.loc[:, ~csv.columns.str.contains('^Unnamed')]\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfeb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TRANSFORM = torch.nn.Sequential(\n",
    "        torchvision.transforms.Resize(size=224),\n",
    "        torchvision.transforms.CenterCrop(size=224),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=[42.7178, 42.9092, 43.2119, 42.8700, 42.7862, 42.7192, 42.8525],\n",
    "            std =[104.3150, 104.7388, 105.4271, 104.6307, 104.5374, 104.3182, 104.5891]\n",
    "            ),\n",
    "        # torchvision.transforms.ColorJitter(),\n",
    "    )\n",
    "TEST_TRANSFORM  = torch.nn.Sequential(\n",
    "        torchvision.transforms.Resize(size=224),\n",
    "        torchvision.transforms.CenterCrop(size=224),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=[42.7178, 42.9092, 43.2119, 42.8700, 42.7862, 42.7192, 42.8525],\n",
    "            std =[104.3150, 104.7388, 105.4271, 104.6307, 104.5374, 104.3182, 104.5891]\n",
    "            ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20462eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold A\n"
     ]
    }
   ],
   "source": [
    "# Spatially Aware Cross-Validation\n",
    "with open(FOLD_PATH, 'rb') as f:\n",
    "    folds = pickle.load(f)\n",
    "results = dict()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for fold in folds:\n",
    "    writer = SummaryWriter()\n",
    "    r2 = torchmetrics.R2Score().to(device=device)\n",
    "    # Index split\n",
    "    train_split = folds[fold]['train'][:3200]\n",
    "    val_split = folds[fold]['val'][:1280]\n",
    "    test_split = folds[fold]['test'][:1280]\n",
    "    # CSV split\n",
    "    train_df = csv.iloc[train_split]\n",
    "    val_df = csv.iloc[val_split]\n",
    "    test_df = csv.iloc[test_split]\n",
    "    # Datasets\n",
    "    train_dataset = CustomDatasetFromDataFrame(train_df, DATA_DIR, transform=TRAIN_TRANSFORM )\n",
    "    val_dataset = CustomDatasetFromDataFrame(val_df, DATA_DIR, transform=TEST_TRANSFORM )\n",
    "    test_dataset  = CustomDatasetFromDataFrame(test_df, DATA_DIR, transform=TEST_TRANSFORM )\n",
    "    # DataLoaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    # TRANSFER LEARNING SCENARIO\n",
    "    base_model = torchgeo.models.resnet18(weights=torchgeo.models.ResNet18_Weights.SENTINEL2_ALL_MOCO)\n",
    "    model = build_from_config( base_model=base_model, config_file=CONFIG_FILE )\n",
    "    model = model.to(device=device)\n",
    "    # print(torchinfo.summary(\n",
    "    #     model, \n",
    "    #     input_size=(int(config['batch_size']), 7, 224, 224), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n",
    "    #     verbose=0,\n",
    "    #     col_names=[\"input_size\",\"trainable\"],\n",
    "    #     col_width=20,\n",
    "    #     row_settings=[\"var_names\"]\n",
    "    # ))\n",
    "    # CONFIGURE LOSS, OPTIM\n",
    "    loss_fn = utils.configure_loss( config )\n",
    "    optimizer = utils.configure_optimizer( config, model )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer)\n",
    "    print(f\"Training on fold {fold}\")\n",
    "    results = train(\n",
    "    model=model,\n",
    "    train_dataloader=val_loader,\n",
    "    val_dataloader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=config['n_epochs'],\n",
    "    batch_size=config['batch_size'],\n",
    "    in_channels=config['in_channels'],\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    r2=r2\n",
    "    )\n",
    "    torch.save(model.state_dict(), config['checkpoint_path']+str(fold)+\".pth\")\n",
    "    utils.free_gpu_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccb8ae5a",
   "metadata": {},
   "source": [
    "3. Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db74dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_r2, Y_true, Y_pred = test(model=model, dataloader=val_loader, device=device)\n",
    "# Y_true = [ utils.denormalize_asset(asset) for asset in Y_true]\n",
    "# Y_pred = [ utils.denormalize_asset(asset) for asset in Y_pred]\n",
    "results = pd.DataFrame({\n",
    "    'true index':np.array(Y_true),\n",
    "    'predicted index':np.array(Y_pred)\n",
    "})\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"rocket\")\n",
    "sns.regplot(x='true index', y='predicted index', data=results).set(title='R2 = '+str(test_r2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
