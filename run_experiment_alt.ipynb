{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee11b763",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065c3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117e1d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchinfo\n",
    "import torch \n",
    "import torchmetrics\n",
    "import torchgeo.models\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from models.from_config import build_from_config\n",
    "from data_handlers.csv_dataset import CustomDatasetFromDataFrame\n",
    "from utils import utils\n",
    "from train import train\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77550fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH=os.path.join('data','geometry_less_dataset.csv')\n",
    "DATA_DIR=os.path.join('data','landsat_tif','')\n",
    "FOLD_PATH=os.path.join('data','dhs_incountry_folds.pkl')\n",
    "CONFIG_FILE = os.path.join('configs','resnet18_ms_e2e_l7_1e2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5da8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>households</th>\n",
       "      <th>wealthpooled</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.350257</td>\n",
       "      <td>13.534922</td>\n",
       "      <td>36</td>\n",
       "      <td>2.312757</td>\n",
       "      <td>-12_3_13_53.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.360865</td>\n",
       "      <td>13.551494</td>\n",
       "      <td>32</td>\n",
       "      <td>2.010293</td>\n",
       "      <td>-12_3_13_55.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>-12.613421</td>\n",
       "      <td>13.413085</td>\n",
       "      <td>36</td>\n",
       "      <td>0.877744</td>\n",
       "      <td>-12_6_13_41.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>-12.581454</td>\n",
       "      <td>13.397711</td>\n",
       "      <td>35</td>\n",
       "      <td>1.066994</td>\n",
       "      <td>-12_5_13_39.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>-12.578135</td>\n",
       "      <td>13.418748</td>\n",
       "      <td>37</td>\n",
       "      <td>1.750153</td>\n",
       "      <td>-12_5_13_41.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year  cluster        lat        lon  households  wealthpooled  \\\n",
       "0  angola  2011        1 -12.350257  13.534922          36      2.312757   \n",
       "1  angola  2011        2 -12.360865  13.551494          32      2.010293   \n",
       "2  angola  2011        3 -12.613421  13.413085          36      0.877744   \n",
       "3  angola  2011        4 -12.581454  13.397711          35      1.066994   \n",
       "4  angola  2011        5 -12.578135  13.418748          37      1.750153   \n",
       "\n",
       "          filename  \n",
       "0  -12_3_13_53.tif  \n",
       "1  -12_3_13_55.tif  \n",
       "2  -12_6_13_41.tif  \n",
       "3  -12_5_13_39.tif  \n",
       "4  -12_5_13_41.tif  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open( CONFIG_FILE ) as f:\n",
    "    config = json.load(f)\n",
    "csv = pd.read_csv(CSV_PATH)\n",
    "csv['filename']=csv.apply(\n",
    "    lambda row:  str(row['lat'])[:5].replace('.','_')+\"_\"+str(row.lon)[:5].replace('.','_')+'.tif', axis=1\n",
    ")\n",
    "csv = csv.loc[:, ~csv.columns.str.contains('^Unnamed')]\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adfeb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TRANSFORM = torch.nn.Sequential(\n",
    "        torchvision.transforms.Resize(size=256),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        torchvision.transforms.ColorJitter(),\n",
    "    )\n",
    "TEST_TRANSFORM  = torch.nn.Sequential(\n",
    "        torchvision.transforms.Resize(size=256),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20462eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Layer (type (var_name))                  Input Shape          Trainable\n",
      "================================================================================\n",
      "ResNet (ResNet)                          [128, 7, 256, 256]   True\n",
      "├─Conv2d (conv1)                         [128, 7, 256, 256]   True\n",
      "├─BatchNorm2d (bn1)                      [128, 64, 128, 128]  True\n",
      "├─ReLU (act1)                            [128, 64, 128, 128]  --\n",
      "├─MaxPool2d (maxpool)                    [128, 64, 128, 128]  --\n",
      "├─Sequential (layer1)                    [128, 64, 64, 64]    True\n",
      "│    └─BasicBlock (0)                    [128, 64, 64, 64]    True\n",
      "│    │    └─Conv2d (conv1)               [128, 64, 64, 64]    True\n",
      "│    │    └─BatchNorm2d (bn1)            [128, 64, 64, 64]    True\n",
      "│    │    └─ReLU (act1)                  [128, 64, 64, 64]    --\n",
      "│    │    └─Conv2d (conv2)               [128, 64, 64, 64]    True\n",
      "│    │    └─BatchNorm2d (bn2)            [128, 64, 64, 64]    True\n",
      "│    │    └─ReLU (act2)                  [128, 64, 64, 64]    --\n",
      "│    └─BasicBlock (1)                    [128, 64, 64, 64]    True\n",
      "│    │    └─Conv2d (conv1)               [128, 64, 64, 64]    True\n",
      "│    │    └─BatchNorm2d (bn1)            [128, 64, 64, 64]    True\n",
      "│    │    └─ReLU (act1)                  [128, 64, 64, 64]    --\n",
      "│    │    └─Conv2d (conv2)               [128, 64, 64, 64]    True\n",
      "│    │    └─BatchNorm2d (bn2)            [128, 64, 64, 64]    True\n",
      "│    │    └─ReLU (act2)                  [128, 64, 64, 64]    --\n",
      "├─Sequential (layer2)                    [128, 64, 64, 64]    True\n",
      "│    └─BasicBlock (0)                    [128, 64, 64, 64]    True\n",
      "│    │    └─Conv2d (conv1)               [128, 64, 64, 64]    True\n",
      "│    │    └─BatchNorm2d (bn1)            [128, 128, 32, 32]   True\n",
      "│    │    └─ReLU (act1)                  [128, 128, 32, 32]   --\n",
      "│    │    └─Conv2d (conv2)               [128, 128, 32, 32]   True\n",
      "│    │    └─BatchNorm2d (bn2)            [128, 128, 32, 32]   True\n",
      "│    │    └─Sequential (downsample)      [128, 64, 64, 64]    True\n",
      "│    │    └─ReLU (act2)                  [128, 128, 32, 32]   --\n",
      "│    └─BasicBlock (1)                    [128, 128, 32, 32]   True\n",
      "│    │    └─Conv2d (conv1)               [128, 128, 32, 32]   True\n",
      "│    │    └─BatchNorm2d (bn1)            [128, 128, 32, 32]   True\n",
      "│    │    └─ReLU (act1)                  [128, 128, 32, 32]   --\n",
      "│    │    └─Conv2d (conv2)               [128, 128, 32, 32]   True\n",
      "│    │    └─BatchNorm2d (bn2)            [128, 128, 32, 32]   True\n",
      "│    │    └─ReLU (act2)                  [128, 128, 32, 32]   --\n",
      "├─Sequential (layer3)                    [128, 128, 32, 32]   True\n",
      "│    └─BasicBlock (0)                    [128, 128, 32, 32]   True\n",
      "│    │    └─Conv2d (conv1)               [128, 128, 32, 32]   True\n",
      "│    │    └─BatchNorm2d (bn1)            [128, 256, 16, 16]   True\n",
      "│    │    └─ReLU (act1)                  [128, 256, 16, 16]   --\n",
      "│    │    └─Conv2d (conv2)               [128, 256, 16, 16]   True\n",
      "│    │    └─BatchNorm2d (bn2)            [128, 256, 16, 16]   True\n",
      "│    │    └─Sequential (downsample)      [128, 128, 32, 32]   True\n",
      "│    │    └─ReLU (act2)                  [128, 256, 16, 16]   --\n",
      "│    └─BasicBlock (1)                    [128, 256, 16, 16]   True\n",
      "│    │    └─Conv2d (conv1)               [128, 256, 16, 16]   True\n",
      "│    │    └─BatchNorm2d (bn1)            [128, 256, 16, 16]   True\n",
      "│    │    └─ReLU (act1)                  [128, 256, 16, 16]   --\n",
      "│    │    └─Conv2d (conv2)               [128, 256, 16, 16]   True\n",
      "│    │    └─BatchNorm2d (bn2)            [128, 256, 16, 16]   True\n",
      "│    │    └─ReLU (act2)                  [128, 256, 16, 16]   --\n",
      "├─Sequential (layer4)                    [128, 256, 16, 16]   True\n",
      "│    └─BasicBlock (0)                    [128, 256, 16, 16]   True\n",
      "│    │    └─Conv2d (conv1)               [128, 256, 16, 16]   True\n",
      "│    │    └─BatchNorm2d (bn1)            [128, 512, 8, 8]     True\n",
      "│    │    └─ReLU (act1)                  [128, 512, 8, 8]     --\n",
      "│    │    └─Conv2d (conv2)               [128, 512, 8, 8]     True\n",
      "│    │    └─BatchNorm2d (bn2)            [128, 512, 8, 8]     True\n",
      "│    │    └─Sequential (downsample)      [128, 256, 16, 16]   True\n",
      "│    │    └─ReLU (act2)                  [128, 512, 8, 8]     --\n",
      "│    └─BasicBlock (1)                    [128, 512, 8, 8]     True\n",
      "│    │    └─Conv2d (conv1)               [128, 512, 8, 8]     True\n",
      "│    │    └─BatchNorm2d (bn1)            [128, 512, 8, 8]     True\n",
      "│    │    └─ReLU (act1)                  [128, 512, 8, 8]     --\n",
      "│    │    └─Conv2d (conv2)               [128, 512, 8, 8]     True\n",
      "│    │    └─BatchNorm2d (bn2)            [128, 512, 8, 8]     True\n",
      "│    │    └─ReLU (act2)                  [128, 512, 8, 8]     --\n",
      "├─SelectAdaptivePool2d (global_pool)     [128, 512, 8, 8]     --\n",
      "│    └─AdaptiveAvgPool2d (pool)          [128, 512, 8, 8]     --\n",
      "│    └─Flatten (flatten)                 [128, 512, 1, 1]     --\n",
      "├─Linear (fc)                            [128, 512]           True\n",
      "================================================================================\n",
      "Total params: 11,189,569\n",
      "Trainable params: 11,189,569\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 329.51\n",
      "================================================================================\n",
      "Input size (MB): 234.88\n",
      "Forward/backward pass size (MB): 6643.78\n",
      "Params size (MB): 44.76\n",
      "Estimated Total Size (MB): 6923.42\n",
      "================================================================================\n",
      "Training on fold A\n",
      "Epoch: 1 | train_loss: 0.0645 | train_r2: -0.3657 | test_loss: 24.8133 | test_r2: -491.1668\n",
      "Epoch: 2 | train_loss: 0.0446 | train_r2: 0.0334 | test_loss: 0.0952 | test_r2: -0.8834\n",
      "Epoch: 3 | train_loss: 0.0439 | train_r2: 0.0498 | test_loss: 0.0696 | test_r2: -0.3598\n",
      "Epoch: 4 | train_loss: 0.0459 | train_r2: 0.0116 | test_loss: 0.0573 | test_r2: -0.1254\n",
      "Epoch: 5 | train_loss: 0.0389 | train_r2: 0.1518 | test_loss: 0.0939 | test_r2: -0.8485\n",
      "Epoch: 6 | train_loss: 0.0313 | train_r2: 0.3208 | test_loss: 0.1014 | test_r2: -1.0013\n",
      "Epoch: 7 | train_loss: 0.0276 | train_r2: 0.4028 | test_loss: 0.0644 | test_r2: -0.2578\n",
      "Epoch: 8 | train_loss: 0.0286 | train_r2: 0.3808 | test_loss: 0.1147 | test_r2: -1.2441\n",
      "Epoch: 9 | train_loss: 0.0259 | train_r2: 0.4407 | test_loss: 0.0609 | test_r2: -0.1851\n",
      "Epoch: 10 | train_loss: 0.0243 | train_r2: 0.4692 | test_loss: 0.0825 | test_r2: -0.6164\n",
      "Epoch: 11 | train_loss: 0.0294 | train_r2: 0.3654 | test_loss: 0.3010 | test_r2: -4.9788\n",
      "Epoch: 12 | train_loss: 0.0256 | train_r2: 0.4457 | test_loss: 0.0976 | test_r2: -0.9567\n",
      "Epoch: 13 | train_loss: 0.0226 | train_r2: 0.5100 | test_loss: 0.0946 | test_r2: -0.9097\n",
      "Epoch: 14 | train_loss: 0.0259 | train_r2: 0.4421 | test_loss: 0.0640 | test_r2: -0.2673\n",
      "Epoch: 15 | train_loss: 0.0240 | train_r2: 0.4793 | test_loss: 0.0868 | test_r2: -0.7052\n",
      "Epoch: 16 | train_loss: 0.0219 | train_r2: 0.5266 | test_loss: 0.0769 | test_r2: -0.5086\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mReduceLROnPlateau(optimizer\u001b[39m=\u001b[39moptimizer)\n\u001b[1;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining on fold \u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m results[fold] \u001b[39m=\u001b[39m train(\n\u001b[1;32m     63\u001b[0m model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     64\u001b[0m train_dataloader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[1;32m     65\u001b[0m val_dataloader\u001b[39m=\u001b[39;49mval_loader,\n\u001b[1;32m     66\u001b[0m optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     67\u001b[0m scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[1;32m     68\u001b[0m loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m     69\u001b[0m epochs\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mn_epochs\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     70\u001b[0m batch_size\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     71\u001b[0m in_channels\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39min_channels\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     72\u001b[0m writer\u001b[39m=\u001b[39;49mwriter,\n\u001b[1;32m     73\u001b[0m device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     74\u001b[0m r2\u001b[39m=\u001b[39;49mr2\n\u001b[1;32m     75\u001b[0m )\n\u001b[1;32m     76\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), config[\u001b[39m'\u001b[39m\u001b[39mcheckpoint_path\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_fold_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(fold)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/matthieu/LaCie/2-mpa/train.py:138\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, scheduler, loss_fn, epochs, batch_size, in_channels, device, writer, r2)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39m# Loop through training and testing steps for a number of epochs\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m--> 138\u001b[0m     train_loss, train_r2 \u001b[39m=\u001b[39m train_step(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    139\u001b[0m                                        dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m    140\u001b[0m                                        loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m    141\u001b[0m                                        optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    142\u001b[0m                                        device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    143\u001b[0m                                        r2\u001b[39m=\u001b[39;49mr2)\n\u001b[1;32m    144\u001b[0m     test_loss, test_r2 \u001b[39m=\u001b[39m val_step(model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    145\u001b[0m                                   dataloader\u001b[39m=\u001b[39mval_dataloader,\n\u001b[1;32m    146\u001b[0m                                   loss_fn\u001b[39m=\u001b[39mloss_fn,\n\u001b[1;32m    147\u001b[0m                                   device\u001b[39m=\u001b[39mdevice,\n\u001b[1;32m    148\u001b[0m                                   r2\u001b[39m=\u001b[39mr2)\n\u001b[1;32m    149\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n",
      "File \u001b[0;32m/media/matthieu/LaCie/2-mpa/train.py:22\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer, device, r2)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m# Loop through data loader data batches\u001b[39;00m\n\u001b[1;32m     21\u001b[0m score \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):        \n\u001b[1;32m     23\u001b[0m     \u001b[39m# Send data to target device\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mfloat(), y\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     25\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1272\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1271\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1272\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1273\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1274\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mpa_env/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/anaconda3/envs/mpa_env/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Spatially Aware Cross-Validation\n",
    "with open(FOLD_PATH, 'rb') as f:\n",
    "    folds = pickle.load(f)\n",
    "results = dict()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for fold in folds:\n",
    "    writer = SummaryWriter()\n",
    "    r2 = torchmetrics.R2Score().to(device=device)\n",
    "    # Index split\n",
    "    train_split = folds[fold]['train'][:2560]\n",
    "    val_split = folds[fold]['val'][:1280]\n",
    "    # test_split = folds[fold]['test']\n",
    "    # CSV split\n",
    "    train_df = csv.iloc[train_split]\n",
    "    val_df = csv.iloc[val_split]\n",
    "    # test_df = csv.iloc[test_split]\n",
    "    # Datasets\n",
    "    train_dataset = CustomDatasetFromDataFrame(train_df, DATA_DIR, transform=TRAIN_TRANSFORM )\n",
    "    val_dataset = CustomDatasetFromDataFrame(val_df, DATA_DIR, transform=TEST_TRANSFORM )\n",
    "    # test_dataset  = CustomDatasetFromDataFrame(test_df, DATA_DIR, transform=TEST_TRANSFORM )\n",
    "    # DataLoaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    # test_loader = torch.utils.data.DataLoader(\n",
    "    #     test_dataset,\n",
    "    #     batch_size=64,\n",
    "    #     shuffle=True,\n",
    "    #     num_workers=4,\n",
    "    #     pin_memory=True\n",
    "    # )\n",
    "    # TRANSFER LEARNING SCENARIO\n",
    "    # base_model = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "    base_model = torchgeo.models.resnet18(weights=torchgeo.models.ResNet18_Weights.SENTINEL2_ALL_MOCO)\n",
    "    model = build_from_config( base_model=base_model, config_file=CONFIG_FILE )\n",
    "    model = model.to(device=device)\n",
    "    print(torchinfo.summary(\n",
    "        model, \n",
    "        input_size=(int(config['batch_size']), 7, 256, 256), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n",
    "        verbose=0,\n",
    "        col_names=[\"input_size\",\"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "    ))\n",
    "    # CONFIGURE LOSS, OPTIM\n",
    "    loss_fn = utils.configure_loss( config )\n",
    "    optimizer = utils.configure_optimizer( config, model )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer)\n",
    "    print(f\"Training on fold {fold}\")\n",
    "    results[fold] = train(\n",
    "    model=model,\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=config['n_epochs'],\n",
    "    batch_size=config['batch_size'],\n",
    "    in_channels=config['in_channels'],\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    r2=r2\n",
    "    )\n",
    "    torch.save(model.state_dict(), config['checkpoint_path']+'_fold_'+str(fold)+\".pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccb8ae5a",
   "metadata": {},
   "source": [
    "3. Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db74dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_r2, Y_true, Y_pred = test(model=model, dataloader=val_loader, device=device)\n",
    "# Y_true = [ utils.denormalize_asset(asset) for asset in Y_true]\n",
    "# Y_pred = [ utils.denormalize_asset(asset) for asset in Y_pred]\n",
    "results = pd.DataFrame({\n",
    "    'true index':np.array(Y_true),\n",
    "    'predicted index':np.array(Y_pred)\n",
    "})\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"rocket\")\n",
    "sns.regplot(x='true index', y='predicted index', data=results).set(title='R2 = '+str(test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68768d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01ed5c42258d104453582e2fee2faf5d01150c2a161fd6cc7123c0fdfe444c60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
