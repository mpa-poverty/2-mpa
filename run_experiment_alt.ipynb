{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee11b763",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065c3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "117e1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models.from_config import build_from_config\n",
    "from models.double_branch import DoubleBranchCNN\n",
    "from data_handlers.csv_dataset import CustomDatasetFromDataFrame\n",
    "from utils import utils\n",
    "from utils import transfer_learning as tl\n",
    "from train import train, dual_train\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e77550fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH=os.path.join('data','wealth_index.csv')\n",
    "DATA_DIR=os.path.join('data','landsat_7','')\n",
    "FOLD_PATH=os.path.join('data','dhs_incountry_folds.pkl')\n",
    "CONFIG_FILE_MS = os.path.join('configs','resnet18_ms_e2e_l7_yeh.json')\n",
    "CONFIG_FILE_MSNL = os.path.join('configs','resnet18_msnl_e2e_l7_yeh.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e5da8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>households</th>\n",
       "      <th>wealthpooled</th>\n",
       "      <th>geometry</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.350257</td>\n",
       "      <td>13.534922</td>\n",
       "      <td>36</td>\n",
       "      <td>2.312757</td>\n",
       "      <td>POINT (1506700.58557273 -1385596.0684884773)</td>\n",
       "      <td>-12_3_13_53.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.360865</td>\n",
       "      <td>13.551494</td>\n",
       "      <td>32</td>\n",
       "      <td>2.010293</td>\n",
       "      <td>POINT (1508545.372017885 -1386804.9130245172)</td>\n",
       "      <td>-12_3_13_55.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>-12.613421</td>\n",
       "      <td>13.413085</td>\n",
       "      <td>36</td>\n",
       "      <td>0.877744</td>\n",
       "      <td>POINT (1493137.790366379 -1415600.6075743325)</td>\n",
       "      <td>-12_6_13_41.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>-12.581454</td>\n",
       "      <td>13.397711</td>\n",
       "      <td>35</td>\n",
       "      <td>1.066994</td>\n",
       "      <td>POINT (1491426.3440705661 -1411954.2588894619)</td>\n",
       "      <td>-12_5_13_39.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>-12.578135</td>\n",
       "      <td>13.418748</td>\n",
       "      <td>37</td>\n",
       "      <td>1.750153</td>\n",
       "      <td>POINT (1493768.1835246533 -1411575.617279712)</td>\n",
       "      <td>-12_5_13_41.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year  cluster        lat        lon  households  wealthpooled  \\\n",
       "0  angola  2011        1 -12.350257  13.534922          36      2.312757   \n",
       "1  angola  2011        2 -12.360865  13.551494          32      2.010293   \n",
       "2  angola  2011        3 -12.613421  13.413085          36      0.877744   \n",
       "3  angola  2011        4 -12.581454  13.397711          35      1.066994   \n",
       "4  angola  2011        5 -12.578135  13.418748          37      1.750153   \n",
       "\n",
       "                                         geometry         filename  \n",
       "0    POINT (1506700.58557273 -1385596.0684884773)  -12_3_13_53.tif  \n",
       "1   POINT (1508545.372017885 -1386804.9130245172)  -12_3_13_55.tif  \n",
       "2   POINT (1493137.790366379 -1415600.6075743325)  -12_6_13_41.tif  \n",
       "3  POINT (1491426.3440705661 -1411954.2588894619)  -12_5_13_39.tif  \n",
       "4   POINT (1493768.1835246533 -1411575.617279712)  -12_5_13_41.tif  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open( CONFIG_FILE_MS ) as f:\n",
    "    config_ms = json.load(f)\n",
    "with open( CONFIG_FILE_MSNL ) as f:\n",
    "    config_msnl = json.load(f)\n",
    "csv = pd.read_csv(CSV_PATH)\n",
    "# csv['filename']=csv.apply(\n",
    "#     lambda row:  str(row['lat'])[:5].replace('.','_')+\"_\"+str(row.lon)[:5].replace('.','_')+'.tif', axis=1\n",
    "# )\n",
    "csv.drop(\"bounding_box\", axis=1, inplace=True)\n",
    "csv = csv.loc[:, ~csv.columns.str.contains('^Unnamed')]\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adfeb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TRANSFORM = torch.nn.Sequential(\n",
    "        torchvision.transforms.CenterCrop(size=224),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        torchvision.transforms.ColorJitter(),\n",
    "    )\n",
    "TEST_TRANSFORM  = torch.nn.Sequential(\n",
    "        torchvision.transforms.CenterCrop(size=224),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20462eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold A\n"
     ]
    },
    {
     "ename": "RasterioIOError",
     "evalue": "Caught RasterioIOError in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"rasterio/_base.pyx\", line 308, in rasterio._base.DatasetBase.__init__\n  File \"rasterio/_base.pyx\", line 219, in rasterio._base.open_dataset\n  File \"rasterio/_err.pyx\", line 221, in rasterio._err.exc_wrap_pointer\nrasterio._err.CPLE_OpenFailedError: data/landsat_7/2_531_34_60.tif: No such file or directory\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/media/matthieu/LaCie/2-mpa/data_handlers/csv_dataset.py\", line 36, in __getitem__\n    tile = np.array(rio.open(tile_name).read())\n  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/rasterio/env.py\", line 451, in wrapper\n    return f(*args, **kwds)\n  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/rasterio/__init__.py\", line 304, in open\n    dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n  File \"rasterio/_base.pyx\", line 310, in rasterio._base.DatasetBase.__init__\nrasterio.errors.RasterioIOError: data/landsat_7/2_531_34_60.tif: No such file or directory\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m     scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mReduceLROnPlateau(optimizer\u001b[39m=\u001b[39moptimizer)\n\u001b[1;32m     53\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining on fold \u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m     results[fold] \u001b[39m=\u001b[39m train(\n\u001b[1;32m     55\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     56\u001b[0m         train_dataloader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[1;32m     57\u001b[0m         val_dataloader\u001b[39m=\u001b[39;49mval_loader,\n\u001b[1;32m     58\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     59\u001b[0m         scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[1;32m     60\u001b[0m         loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m     61\u001b[0m         epochs\u001b[39m=\u001b[39;49mconfig_ms[\u001b[39m'\u001b[39;49m\u001b[39mn_epochs\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     62\u001b[0m         batch_size\u001b[39m=\u001b[39;49mconfig_ms[\u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     63\u001b[0m         in_channels\u001b[39m=\u001b[39;49mconfig_ms[\u001b[39m'\u001b[39;49m\u001b[39min_channels\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     64\u001b[0m         writer\u001b[39m=\u001b[39;49mwriter,\n\u001b[1;32m     65\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     66\u001b[0m         r2\u001b[39m=\u001b[39;49mr2\n\u001b[1;32m     67\u001b[0m     )\n\u001b[1;32m     68\u001b[0m     torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), config_ms[\u001b[39m'\u001b[39m\u001b[39mcheckpoint_path\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_fold_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(fold)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m final_results \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mcompute_average_crossval_results(results\u001b[39m=\u001b[39mresults)\n",
      "File \u001b[0;32m/media/matthieu/LaCie/2-mpa/train.py:137\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, scheduler, loss_fn, epochs, batch_size, in_channels, device, writer, r2)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Loop through training and testing steps for a number of epochs\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m--> 137\u001b[0m     train_loss, train_r2 \u001b[39m=\u001b[39m train_step(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    138\u001b[0m                                        dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m    139\u001b[0m                                        loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m    140\u001b[0m                                        optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    141\u001b[0m                                        device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    142\u001b[0m                                        r2\u001b[39m=\u001b[39;49mr2)\n\u001b[1;32m    143\u001b[0m     test_loss, test_r2 \u001b[39m=\u001b[39m val_step(model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    144\u001b[0m                                   dataloader\u001b[39m=\u001b[39mval_dataloader,\n\u001b[1;32m    145\u001b[0m                                   loss_fn\u001b[39m=\u001b[39mloss_fn,\n\u001b[1;32m    146\u001b[0m                                   device\u001b[39m=\u001b[39mdevice,\n\u001b[1;32m    147\u001b[0m                                   r2\u001b[39m=\u001b[39mr2)\n\u001b[1;32m    148\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n",
      "File \u001b[0;32m/media/matthieu/LaCie/2-mpa/train.py:22\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer, device, r2)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m# Loop through data loader data batches\u001b[39;00m\n\u001b[1;32m     21\u001b[0m score \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):        \n\u001b[1;32m     23\u001b[0m     \u001b[39m# Send data to target device\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mfloat(), y\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     25\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1313\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rcvd_idx]) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1312\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info\u001b[39m.\u001b[39mpop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rcvd_idx)[\u001b[39m1\u001b[39m]\n\u001b[0;32m-> 1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_data()\n",
      "File \u001b[0;32m~/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1360\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 543\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: Caught RasterioIOError in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"rasterio/_base.pyx\", line 308, in rasterio._base.DatasetBase.__init__\n  File \"rasterio/_base.pyx\", line 219, in rasterio._base.open_dataset\n  File \"rasterio/_err.pyx\", line 221, in rasterio._err.exc_wrap_pointer\nrasterio._err.CPLE_OpenFailedError: data/landsat_7/2_531_34_60.tif: No such file or directory\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/media/matthieu/LaCie/2-mpa/data_handlers/csv_dataset.py\", line 36, in __getitem__\n    tile = np.array(rio.open(tile_name).read())\n  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/rasterio/env.py\", line 451, in wrapper\n    return f(*args, **kwds)\n  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/rasterio/__init__.py\", line 304, in open\n    dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n  File \"rasterio/_base.pyx\", line 310, in rasterio._base.DatasetBase.__init__\nrasterio.errors.RasterioIOError: data/landsat_7/2_531_34_60.tif: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Spatially Aware Cross-Validation\n",
    "with open(FOLD_PATH, 'rb') as f:\n",
    "    folds = pickle.load(f)\n",
    "results = dict()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for fold in folds:\n",
    "    writer = SummaryWriter()\n",
    "    r2 = torchmetrics.R2Score().to(device=device)\n",
    "    # Index split\n",
    "    train_split = folds[fold]['train']\n",
    "    val_split = folds[fold]['val']\n",
    "    test_split = folds[fold]['test']\n",
    "    # CSV split\n",
    "    train_df = csv.iloc[train_split]\n",
    "    val_df = csv.iloc[train_split]\n",
    "    test_df = csv.iloc[test_split]\n",
    "    # Datasets\n",
    "    train_dataset = CustomDatasetFromDataFrame(train_df, DATA_DIR,transform=TRAIN_TRANSFORM )\n",
    "    val_dataset = CustomDatasetFromDataFrame(val_df, DATA_DIR, transform=TEST_TRANSFORM )\n",
    "    test_dataset  = CustomDatasetFromDataFrame(test_df, DATA_DIR, transform=TEST_TRANSFORM )\n",
    "    # DataLoaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config_ms['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config_ms['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config_ms['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    base_model = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "    # base_model = torchgeo.models.resnet18(weights=torchgeo.models.ResNet18_Weights.SENTINEL2_ALL_MOCO)\n",
    "    ms_branch = build_from_config( base_model=base_model, config_file=CONFIG_FILE_MS )\n",
    "    # nl_branch = tl.update_single_layer(torchvision.models.resnet18())\n",
    "    # model = DoubleBranchCNN(b1=ms_branch, b2=nl_branch, output_features=1)\n",
    "    model = ms_branch.to(device=device)\n",
    "    # CONFIGURE LOSS, OPTIM\n",
    "    loss_fn = utils.configure_loss( config_ms )\n",
    "    optimizer = utils.configure_optimizer( config_ms, model )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer)\n",
    "    print(f\"Training on fold {fold}\")\n",
    "    results[fold] = train(\n",
    "        model=model,\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=config_ms['n_epochs'],\n",
    "        batch_size=config_ms['batch_size'],\n",
    "        in_channels=config_ms['in_channels'],\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        r2=r2\n",
    "    )\n",
    "    torch.save(model.state_dict(), config_ms['checkpoint_path']+'_fold_'+str(fold)+\".pth\")\n",
    "final_results = utils.compute_average_crossval_results(results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e37d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dabce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatially Aware Cross-Validation\n",
    "with open(FOLD_PATH, 'rb') as f:\n",
    "    folds = pickle.load(f)\n",
    "results = dict()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for fold in folds:\n",
    "    writer = SummaryWriter()\n",
    "    r2 = torchmetrics.R2Score().to(device=device)\n",
    "    # Index split\n",
    "    train_split = folds[fold]['train']\n",
    "    val_split = folds[fold]['val']\n",
    "    test_split = folds[fold]['test']\n",
    "    # CSV split\n",
    "    train_df = csv.iloc[train_split]\n",
    "    val_df = csv.iloc[train_split]\n",
    "    test_df = csv.iloc[test_split]\n",
    "    # Datasets\n",
    "    train_dataset = CustomDatasetFromDataFrame(train_df, DATA_DIR,transform=TRAIN_TRANSFORM )\n",
    "    val_dataset = CustomDatasetFromDataFrame(val_df, DATA_DIR, transform=TEST_TRANSFORM )\n",
    "    test_dataset  = CustomDatasetFromDataFrame(test_df, DATA_DIR, transform=TEST_TRANSFORM )\n",
    "    # DataLoaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config_msnl['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config_msnl['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config_msnl['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    base_model = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "    # base_model = torchgeo.models.resnet18(weights=torchgeo.models.ResNet18_Weights.SENTINEL2_ALL_MOCO)\n",
    "    ms_branch = build_from_config( base_model=base_model, config_file=CONFIG_FILE_MSNL )\n",
    "    nl_branch = tl.update_single_layer(torchvision.models.resnet18())\n",
    "    model = DoubleBranchCNN(b1=ms_branch, b2=nl_branch, output_features=1)\n",
    "    model = model.to(device=device)\n",
    "    # CONFIGURE LOSS, OPTIM\n",
    "    loss_fn = utils.configure_loss( config_msnl )\n",
    "    optimizer = utils.configure_optimizer( config_msnl, model )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer)\n",
    "    print(f\"Training on fold {fold}\")\n",
    "    results[fold] = dual_train(\n",
    "        model=model,\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=config_msnl['n_epochs'],\n",
    "        batch_size=config_msnl['batch_size'],\n",
    "        in_channels=config_msnl['in_channels'],\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        r2=r2\n",
    "    )\n",
    "    torch.save(model.state_dict(), config_msnl['checkpoint_path']+'_fold_'+str(fold)+\".pth\")\n",
    "final_results_nl = utils.compute_average_crossval_results(results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f428df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b5e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac9b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccb8ae5a",
   "metadata": {},
   "source": [
    "3. Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db74dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_r2, Y_true, Y_pred = test(model=model, dataloader=val_loader, device=device)\n",
    "# # Y_true = [ utils.denormalize_asset(asset) for asset in Y_true]\n",
    "# # Y_pred = [ utils.denormalize_asset(asset) for asset in Y_pred]\n",
    "# results = pd.DataFrame({\n",
    "#     'true index':np.array(Y_true),\n",
    "#     'predicted index':np.array(Y_pred)\n",
    "# })\n",
    "# from scipy.stats import pearsonr\n",
    "# import seaborn as sns\n",
    "# sns.set_palette(\"rocket\")\n",
    "# sns.regplot(x='true index', y='predicted index', data=results).set(title='R2 = '+str(test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68768d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01ed5c42258d104453582e2fee2faf5d01150c2a161fd6cc7123c0fdfe444c60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
