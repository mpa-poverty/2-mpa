{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee11b763",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065c3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117e1d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models.from_config import build_from_config\n",
    "from models.double_branch import DoubleBranchCNN\n",
    "from data_handlers.csv_dataset import CustomDatasetFromDataFrame\n",
    "from utils import utils\n",
    "from utils import transfer_learning as tl\n",
    "from train import train, dual_train\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77550fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH=os.path.join('data','dataset.csv')\n",
    "TEST_CSV=os.path.join('data','madagascar_test_dataset.csv')\n",
    "TRAIN_CSV=os.path.join('data','madagascar_train_dataset.csv')\n",
    "DATA_DIR=os.path.join('data','landsat_7','')\n",
    "FOLD_PATH=os.path.join('data','dhs_incountry_folds.pkl')\n",
    "CONFIG_FILE_MS = os.path.join('configs','resnet18_ms_e2e_l7_yeh.json')\n",
    "CONFIG_FILE_MSNL = os.path.join('configs','resnet18_msnl_e2e_l7_yeh.json')\n",
    "TILE_MIN = [-0.0994, -0.0574, -0.0318, -0.0209, -0.0102, -0.0152, 0.0, -0.07087274]\n",
    "TILE_MAX = [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 316.7, 3104.1401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5da8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>households</th>\n",
       "      <th>wealthpooled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.350257</td>\n",
       "      <td>13.534922</td>\n",
       "      <td>36</td>\n",
       "      <td>2.312757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.360865</td>\n",
       "      <td>13.551494</td>\n",
       "      <td>32</td>\n",
       "      <td>2.010293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>-12.613421</td>\n",
       "      <td>13.413085</td>\n",
       "      <td>36</td>\n",
       "      <td>0.877744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>-12.581454</td>\n",
       "      <td>13.397711</td>\n",
       "      <td>35</td>\n",
       "      <td>1.066994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>-12.578135</td>\n",
       "      <td>13.418748</td>\n",
       "      <td>37</td>\n",
       "      <td>1.750153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index country  year  cluster        lat        lon  households  \\\n",
       "0      0  angola  2011        1 -12.350257  13.534922          36   \n",
       "1      1  angola  2011        2 -12.360865  13.551494          32   \n",
       "2      2  angola  2011        3 -12.613421  13.413085          36   \n",
       "3      3  angola  2011        4 -12.581454  13.397711          35   \n",
       "4      4  angola  2011        5 -12.578135  13.418748          37   \n",
       "\n",
       "   wealthpooled  \n",
       "0      2.312757  \n",
       "1      2.010293  \n",
       "2      0.877744  \n",
       "3      1.066994  \n",
       "4      1.750153  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open( CONFIG_FILE_MS ) as f:\n",
    "    config_ms = json.load(f)\n",
    "with open( CONFIG_FILE_MSNL ) as f:\n",
    "    config_msnl = json.load(f)\n",
    "csv = pd.read_csv(CSV_PATH)\n",
    "# csv.drop(\"bounding_box\", axis=1, inplace=True)\n",
    "# csv = csv.loc[:, ~csv.columns.str.contains('^Unnamed')]\n",
    "csv.reset_index(inplace=True)\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e28af04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE THE MEAN AND STD OF NORMED IMAGES OVER THE COMPLETE DATASET\n",
    "# EXECUTE ONCE -> to script\n",
    "\n",
    "# TEST_TRANSFORM  = torch.nn.Sequential(\n",
    "#         torchvision.transforms.CenterCrop(size=224),\n",
    "#     )\n",
    "# dummy_dataset = CustomDatasetFromDataFrame(csv,\n",
    "#                                            DATA_DIR,\n",
    "#                                            transform=TEST_TRANSFORM,\n",
    "#                                            tile_max=TILE_MAX,\n",
    "#                                            tile_min=TILE_MIN)\n",
    "# dummy_loader = torch.utils.data.DataLoader(\n",
    "#         dummy_dataset, \n",
    "#         batch_size=64\n",
    "#     )\n",
    "\n",
    "# def compute_mean_and_std(dataloader, batch_size):\n",
    "#     channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "#     for data, _ in dataloader:\n",
    "#         if data is not None:\n",
    "#             weight = data.size()[0] / batch_size\n",
    "#             # Mean over batch, height and width, but not over the channels\n",
    "#             channels_sum += weight*torch.mean(data, dim=[0,2,3])\n",
    "#             channels_squared_sum += weight*torch.mean(data**2, dim=[0,2,3])\n",
    "#             num_batches += weight\n",
    "#     mean = channels_sum / num_batches\n",
    "#     # std = sqrt(E[X^2] - (E[X])^2)\n",
    "#     std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "#     return mean, std\n",
    "\n",
    "# means, stds = compute_mean_and_std(dummy_loader, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a375ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# means, stds\n",
    "means = torch.tensor([0.6952, 0.6890, 0.6851, 0.6834, 0.6818, 0.6826, 0.0043])\n",
    "stds = torch.tensor([9.5266, 9.7209, 9.8435, 9.8968, 9.9495, 9.9249, 0.0632])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db3db94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TRANSFORM = torch.nn.Sequential(\n",
    "        torchvision.transforms.CenterCrop(size=224),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=means,\n",
    "            std=stds\n",
    "        )\n",
    "    )\n",
    "TEST_TRANSFORM  = torch.nn.Sequential(\n",
    "        torchvision.transforms.CenterCrop(size=224),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=means,\n",
    "            std=stds\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609813b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20462eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 16:37:24.034781: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-11 16:37:24.129310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold (All)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 185/498 [08:04<03:19,  1.57it/s]"
     ]
    }
   ],
   "source": [
    "# Spatially Aware Cross-Validation\n",
    "with open(FOLD_PATH, 'rb') as f:\n",
    "    folds = pickle.load(f)\n",
    "results = dict()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# for fold in folds:\n",
    "writer = SummaryWriter()\n",
    "r2 = torchmetrics.R2Score().to(device=device)\n",
    "# Index split\n",
    "csv_train = pd.read_csv('data/madagascar_train_dataset.csv')\n",
    "train_split=np.arange(len(csv_train))\n",
    "csv_test = pd.read_csv('data/madagascar_test_dataset.csv')\n",
    "csv_test.reset_index(inplace=True)\n",
    "val_split=(len(csv_test))\n",
    "# train_split = np.concatenate((folds['A']['train'],folds['B']['train'],folds['C']['train']))\n",
    "# val_split = folds['E']['train']\n",
    "# CSV split\n",
    "# train_df = csv.iloc[train_split]\n",
    "train_df = csv_train\n",
    "# val_df = csv.iloc[val_split]\n",
    "val_df = csv_test\n",
    "# Datasets\n",
    "train_dataset = CustomDatasetFromDataFrame(train_df, DATA_DIR,transform=TRAIN_TRANSFORM,tile_max=TILE_MAX,\n",
    "                                        tile_min=TILE_MIN )\n",
    "val_dataset = CustomDatasetFromDataFrame(val_df, DATA_DIR, transform=TEST_TRANSFORM,tile_max=TILE_MAX,\n",
    "                                        tile_min=TILE_MIN )\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config_ms['batch_size'], \n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config_ms['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "base_model = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "# base_model = torchgeo.models.resnet18(weights=torchgeo.models.ResNet18_Weights.SENTINEL2_ALL_MOCO)\n",
    "ms_branch = build_from_config( base_model=base_model, config_file=CONFIG_FILE_MS )\n",
    "# nl_branch = tl.update_single_layer(torchvision.models.resnet18())\n",
    "# model = DoubleBranchCNN(b1=ms_branch, b2=nl_branch, output_features=1)\n",
    "model = ms_branch.to(device=device)\n",
    "# CONFIGURE LOSS, OPTIM\n",
    "loss_fn = utils.configure_loss( config_ms )\n",
    "optimizer = utils.configure_optimizer( config_ms, model )\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer)\n",
    "# print(f\"Training on fold {fold}\")\n",
    "print(f\"Training on fold (All)\")\n",
    "results = train(\n",
    "    model=model,\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=config_ms['n_epochs'],\n",
    "    batch_size=config_ms['batch_size'],\n",
    "    in_channels=config_ms['in_channels'],\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    ckpt_path=config_ms['checkpoint_path']+'_fold_'+'all'+\".pth\",\n",
    "    r2=r2\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), config_ms['checkpoint_path']+'_fold_'+'all'+\".pth\")\n",
    "# final_results = utils.compute_average_crossval_results(results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e37d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of certifi failed: Traceback (most recent call last):\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/importlib/__init__.py\", line 166, in reload\n",
      "    spec = module.__spec__ = _bootstrap._find_spec(name, pkgpath, target)\n",
      "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1439, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1408, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1366, in _path_importer_cache\n",
      "OSError: [Errno 5] Input/output error\n",
      "]\n",
      "[autoreload of utils.utils failed: Traceback (most recent call last):\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/media/matthieu/LaCie/2-mpa/utils/utils.py\", line 4, in <module>\n",
      "    import geopandas as gpd\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1002, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
      "OSError: [Errno 5] Input/output error\n",
      "]\n",
      "[autoreload of rasterio.session failed: Traceback (most recent call last):\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/rasterio/session.py\", line 13, in <module>\n",
      "    import boto3\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1002, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
      "OSError: [Errno 5] Input/output error\n",
      "]\n",
      "[autoreload of rasterio.env failed: Traceback (most recent call last):\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 496, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 361, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 319, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to ThreadEnv object\n",
      "]\n",
      "[autoreload of rasterio failed: Traceback (most recent call last):\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/importlib/__init__.py\", line 166, in reload\n",
      "    spec = module.__spec__ = _bootstrap._find_spec(name, pkgpath, target)\n",
      "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1439, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1408, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1366, in _path_importer_cache\n",
      "OSError: [Errno 5] Input/output error\n",
      "]\n",
      "[autoreload of data_handlers.csv_dataset failed: Traceback (most recent call last):\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/matthieu/anaconda3/envs/mpa_env/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/media/matthieu/LaCie/2-mpa/data_handlers/csv_dataset.py\", line 6, in <module>\n",
      "    import cv2\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1002, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
      "OSError: [Errno 5] Input/output error\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23fc343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dabce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatially Aware Cross-Validation\n",
    "with open(FOLD_PATH, 'rb') as f:\n",
    "    folds = pickle.load(f)\n",
    "results = dict()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for fold in folds:\n",
    "    writer = SummaryWriter()\n",
    "    r2 = torchmetrics.R2Score().to(device=device)\n",
    "    # Index split\n",
    "    train_split = folds[fold]['train']\n",
    "    val_split = folds[fold]['val']\n",
    "    test_split = folds[fold]['test']\n",
    "    # CSV split\n",
    "    train_df = csv.iloc[train_split]\n",
    "    val_df = csv.iloc[train_split]\n",
    "    test_df = csv.iloc[test_split]\n",
    "    # Datasets\n",
    "    train_dataset = CustomDatasetFromDataFrame(train_df, DATA_DIR,transform=TRAIN_TRANSFORM )\n",
    "    val_dataset = CustomDatasetFromDataFrame(val_df, DATA_DIR, transform=TEST_TRANSFORM )\n",
    "    test_dataset  = CustomDatasetFromDataFrame(test_df, DATA_DIR, transform=TEST_TRANSFORM )\n",
    "    # DataLoaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config_msnl['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config_msnl['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config_msnl['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    base_model = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "    # base_model = torchgeo.models.resnet18(weights=torchgeo.models.ResNet18_Weights.SENTINEL2_ALL_MOCO)\n",
    "    ms_branch = build_from_config( base_model=base_model, config_file=CONFIG_FILE_MSNL )\n",
    "    nl_branch = tl.update_single_layer(torchvision.models.resnet18())\n",
    "    model = DoubleBranchCNN(b1=ms_branch, b2=nl_branch, output_features=1)\n",
    "    model = model.to(device=device)\n",
    "    # CONFIGURE LOSS, OPTIM\n",
    "    loss_fn = utils.configure_loss( config_msnl )\n",
    "    optimizer = utils.configure_optimizer( config_msnl, model )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer)\n",
    "    print(f\"Training on fold {fold}\")\n",
    "    results[fold] = dual_train(\n",
    "        model=model,\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=config_msnl['n_epochs'],\n",
    "        batch_size=config_msnl['batch_size'],\n",
    "        in_channels=config_msnl['in_channels'],\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        r2=r2\n",
    "    )\n",
    "    torch.save(model.state_dict(), config_msnl['checkpoint_path']+'_fold_'+str(fold)+\".pth\")\n",
    "final_results_nl = utils.compute_average_crossval_results(results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f428df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b5e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac9b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccb8ae5a",
   "metadata": {},
   "source": [
    "3. Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db74dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_r2, Y_true, Y_pred = test(model=model, dataloader=val_loader, device=device)\n",
    "# # Y_true = [ utils.denormalize_asset(asset) for asset in Y_true]\n",
    "# # Y_pred = [ utils.denormalize_asset(asset) for asset in Y_pred]\n",
    "# results = pd.DataFrame({\n",
    "#     'true index':np.array(Y_true),\n",
    "#     'predicted index':np.array(Y_pred)\n",
    "# })\n",
    "# from scipy.stats import pearsonr\n",
    "# import seaborn as sns\n",
    "# sns.set_palette(\"rocket\")\n",
    "# sns.regplot(x='true index', y='predicted index', data=results).set(title='R2 = '+str(test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68768d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01ed5c42258d104453582e2fee2faf5d01150c2a161fd6cc7123c0fdfe444c60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
