{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee11b763",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065c3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "117e1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import torch \n",
    "import torchvision\n",
    "import torchmetrics\n",
    "import rasterio as rio\n",
    "import matplotlib.pyplot as plt\n",
    "import torchinfo\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from models.from_config import build_from_config\n",
    "from data_handlers.csv_dataset import CustomDatasetFromDataFrame\n",
    "from utils import utils\n",
    "from train import train\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77550fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH=os.path.join('data','geometry_less_dataset.csv')\n",
    "DATA_DIR=os.path.join('data','landsat_tif','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5da8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>households</th>\n",
       "      <th>wealthpooled</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.350257</td>\n",
       "      <td>13.534922</td>\n",
       "      <td>36</td>\n",
       "      <td>2.312757</td>\n",
       "      <td>-12_3_13_53.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.360865</td>\n",
       "      <td>13.551494</td>\n",
       "      <td>32</td>\n",
       "      <td>2.010293</td>\n",
       "      <td>-12_3_13_55.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>-12.613421</td>\n",
       "      <td>13.413085</td>\n",
       "      <td>36</td>\n",
       "      <td>0.877744</td>\n",
       "      <td>-12_6_13_41.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>-12.581454</td>\n",
       "      <td>13.397711</td>\n",
       "      <td>35</td>\n",
       "      <td>1.066994</td>\n",
       "      <td>-12_5_13_39.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angola</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>-12.578135</td>\n",
       "      <td>13.418748</td>\n",
       "      <td>37</td>\n",
       "      <td>1.750153</td>\n",
       "      <td>-12_5_13_41.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year  cluster        lat        lon  households  wealthpooled  \\\n",
       "0  angola  2011        1 -12.350257  13.534922          36      2.312757   \n",
       "1  angola  2011        2 -12.360865  13.551494          32      2.010293   \n",
       "2  angola  2011        3 -12.613421  13.413085          36      0.877744   \n",
       "3  angola  2011        4 -12.581454  13.397711          35      1.066994   \n",
       "4  angola  2011        5 -12.578135  13.418748          37      1.750153   \n",
       "\n",
       "          filename  \n",
       "0  -12_3_13_53.tif  \n",
       "1  -12_3_13_55.tif  \n",
       "2  -12_6_13_41.tif  \n",
       "3  -12_5_13_39.tif  \n",
       "4  -12_5_13_41.tif  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add filenames:\n",
    "csv = pd.read_csv(CSV_PATH)\n",
    "csv['filename']=csv.apply(\n",
    "    lambda row:  str(row['lat'])[:5].replace('.','_')+\"_\"+str(row.lon)[:5].replace('.','_')+'.tif', axis=1\n",
    ")\n",
    "csv = csv.loc[:, ~csv.columns.str.contains('^Unnamed')]\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adfeb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND SAVE UPDATED CSV\n",
    "# csv.to_csv(CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "516a0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(tile, label, swap_br=True):\n",
    "    tile_rgb = tile[:3,:,:].numpy()\n",
    "    tile_rgb = tile_rgb.transpose((1,2,0))\n",
    "    tile_rgb = (tile_rgb-tile_rgb.min() )/ (tile_rgb.max()-tile_rgb.min())\n",
    "    print(tile_rgb.min(), \" __ \", tile_rgb.max())\n",
    "    if swap_br:\n",
    "        tile_rgb=tile_rgb[:,:,::-1]\n",
    "    plt.figure()\n",
    "    plt.imshow((tile_rgb*255).astype(int))\n",
    "    plt.title('wealth index: '+str(label))\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee648ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE MEAN AND STD OF THE WHOLE DATASET\n",
    "# (DO IT ONCE)\n",
    "tile_names=glob.glob(os.path.join(DATA_DIR)+'*.tif')\n",
    "tiles=torch.stack([torch.from_numpy(np.nan_to_num(np.array(rio.open(tile).read())[:,:,:])) for tile in tile_names])\n",
    "means = tiles.view(7, -1).mean(dim=1)\n",
    "stds = tiles.view(7, -1).std(dim=1)\n",
    "print(means, stds)\n",
    "# last output:\n",
    "# tensor([42.7178, 42.9092, 43.2119, 42.8700, 42.7862, 42.7192, 42.8525]) \n",
    "# tensor([104.3150, 104.7388, 105.4271, 104.6307, 104.5374, 104.3182, 104.5891])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdab8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torch.nn.Sequential(\n",
    "    torchvision.transforms.Resize(size=224),\n",
    "    torchvision.transforms.CenterCrop(size=224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    torchvision.transforms.ColorJitter(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[42.7178, 42.9092, 43.2119, 42.8700, 42.7862, 42.7192, 42.8525],\n",
    "        std =[104.3150, 104.7388, 105.4271, 104.6307, 104.5374, 104.3182, 104.5891]\n",
    "        ),\n",
    ")\n",
    "test_transform  = torch.nn.Sequential(\n",
    "    torchvision.transforms.Resize(size=224),\n",
    "    torchvision.transforms.CenterCrop(size=224),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[42.7178, 42.9092, 43.2119, 42.8700, 42.7862, 42.7192, 42.8525],\n",
    "        std =[104.3150, 104.7388, 105.4271, 104.6307, 104.5374, 104.3182, 104.5891]\n",
    "        ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20462eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_splits = sklearn.model_selection.train_test_split(np.arange(len(csv.cluster.unique())))\n",
    "# train test split\n",
    "train_split = np.array([idx for i in cluster_splits[0] for idx,_ in csv[csv.cluster==i].iterrows()])\n",
    "test_split  = np.array([idx for i in cluster_splits[1] for idx,_ in csv[csv.cluster==i].iterrows()])\n",
    "# train val split\n",
    "np.random.shuffle(train_split)\n",
    "train_split, val_split = train_split[:int(0.9*len(train_split))], train_split[int(0.9*len(train_split)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb1c51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = 'configs/resnet18_ms.json'\n",
    "with open( CONFIG_FILE ) as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adbdcdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = csv.iloc[train_split]\n",
    "val_df = csv.iloc[val_split]\n",
    "test_df = csv.iloc[test_split]\n",
    "\n",
    "train_dataset = CustomDatasetFromDataFrame(train_df, DATA_DIR, transform=train_transform)\n",
    "val_dataset = CustomDatasetFromDataFrame(val_df, DATA_DIR, transform=train_transform)\n",
    "test_dataset  = CustomDatasetFromDataFrame(test_df, DATA_DIR, transform=test_transform)\n",
    "\n",
    "# train_dataset_tl = torch.utils.data.Subset(train_dataset, np.arange(0,128*3))\n",
    "# val_dataset_tl = torch.utils.data.Subset(val_dataset, np.arange(0,128*2))\n",
    "# test_dataset_tl  = torch.utils.data.Subset(test_dataset, np.arange(0,128*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0903aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=3,\n",
    "        pin_memory=True\n",
    "    )\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=3,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=3,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf5bfa0a",
   "metadata": {},
   "source": [
    "2. Model Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4d14196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchgeo.models\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f6d5257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "ResNet (ResNet)                          [64, 7, 224, 224]    [64, 1]              --                   True\n",
       "├─Conv2d (conv1)                         [64, 7, 224, 224]    [64, 64, 112, 112]   21,952               True\n",
       "├─BatchNorm2d (bn1)                      [64, 64, 112, 112]   [64, 64, 112, 112]   128                  True\n",
       "├─ReLU (act1)                            [64, 64, 112, 112]   [64, 64, 112, 112]   --                   --\n",
       "├─MaxPool2d (maxpool)                    [64, 64, 112, 112]   [64, 64, 56, 56]     --                   --\n",
       "├─Sequential (layer1)                    [64, 64, 56, 56]     [64, 64, 56, 56]     --                   True\n",
       "│    └─BasicBlock (0)                    [64, 64, 56, 56]     [64, 64, 56, 56]     --                   True\n",
       "│    │    └─Conv2d (conv1)               [64, 64, 56, 56]     [64, 64, 56, 56]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn1)            [64, 64, 56, 56]     [64, 64, 56, 56]     128                  True\n",
       "│    │    └─ReLU (act1)                  [64, 64, 56, 56]     [64, 64, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [64, 64, 56, 56]     [64, 64, 56, 56]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn2)            [64, 64, 56, 56]     [64, 64, 56, 56]     128                  True\n",
       "│    │    └─ReLU (act2)                  [64, 64, 56, 56]     [64, 64, 56, 56]     --                   --\n",
       "│    └─BasicBlock (1)                    [64, 64, 56, 56]     [64, 64, 56, 56]     --                   True\n",
       "│    │    └─Conv2d (conv1)               [64, 64, 56, 56]     [64, 64, 56, 56]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn1)            [64, 64, 56, 56]     [64, 64, 56, 56]     128                  True\n",
       "│    │    └─ReLU (act1)                  [64, 64, 56, 56]     [64, 64, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [64, 64, 56, 56]     [64, 64, 56, 56]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn2)            [64, 64, 56, 56]     [64, 64, 56, 56]     128                  True\n",
       "│    │    └─ReLU (act2)                  [64, 64, 56, 56]     [64, 64, 56, 56]     --                   --\n",
       "├─Sequential (layer2)                    [64, 64, 56, 56]     [64, 128, 28, 28]    --                   True\n",
       "│    └─BasicBlock (0)                    [64, 64, 56, 56]     [64, 128, 28, 28]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [64, 64, 56, 56]     [64, 128, 28, 28]    73,728               True\n",
       "│    │    └─BatchNorm2d (bn1)            [64, 128, 28, 28]    [64, 128, 28, 28]    256                  True\n",
       "│    │    └─ReLU (act1)                  [64, 128, 28, 28]    [64, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [64, 128, 28, 28]    [64, 128, 28, 28]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn2)            [64, 128, 28, 28]    [64, 128, 28, 28]    256                  True\n",
       "│    │    └─Sequential (downsample)      [64, 64, 56, 56]     [64, 128, 28, 28]    8,448                True\n",
       "│    │    └─ReLU (act2)                  [64, 128, 28, 28]    [64, 128, 28, 28]    --                   --\n",
       "│    └─BasicBlock (1)                    [64, 128, 28, 28]    [64, 128, 28, 28]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [64, 128, 28, 28]    [64, 128, 28, 28]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn1)            [64, 128, 28, 28]    [64, 128, 28, 28]    256                  True\n",
       "│    │    └─ReLU (act1)                  [64, 128, 28, 28]    [64, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [64, 128, 28, 28]    [64, 128, 28, 28]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn2)            [64, 128, 28, 28]    [64, 128, 28, 28]    256                  True\n",
       "│    │    └─ReLU (act2)                  [64, 128, 28, 28]    [64, 128, 28, 28]    --                   --\n",
       "├─Sequential (layer3)                    [64, 128, 28, 28]    [64, 256, 14, 14]    --                   True\n",
       "│    └─BasicBlock (0)                    [64, 128, 28, 28]    [64, 256, 14, 14]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [64, 128, 28, 28]    [64, 256, 14, 14]    294,912              True\n",
       "│    │    └─BatchNorm2d (bn1)            [64, 256, 14, 14]    [64, 256, 14, 14]    512                  True\n",
       "│    │    └─ReLU (act1)                  [64, 256, 14, 14]    [64, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [64, 256, 14, 14]    [64, 256, 14, 14]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn2)            [64, 256, 14, 14]    [64, 256, 14, 14]    512                  True\n",
       "│    │    └─Sequential (downsample)      [64, 128, 28, 28]    [64, 256, 14, 14]    33,280               True\n",
       "│    │    └─ReLU (act2)                  [64, 256, 14, 14]    [64, 256, 14, 14]    --                   --\n",
       "│    └─BasicBlock (1)                    [64, 256, 14, 14]    [64, 256, 14, 14]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [64, 256, 14, 14]    [64, 256, 14, 14]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn1)            [64, 256, 14, 14]    [64, 256, 14, 14]    512                  True\n",
       "│    │    └─ReLU (act1)                  [64, 256, 14, 14]    [64, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [64, 256, 14, 14]    [64, 256, 14, 14]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn2)            [64, 256, 14, 14]    [64, 256, 14, 14]    512                  True\n",
       "│    │    └─ReLU (act2)                  [64, 256, 14, 14]    [64, 256, 14, 14]    --                   --\n",
       "├─Sequential (layer4)                    [64, 256, 14, 14]    [64, 512, 7, 7]      --                   True\n",
       "│    └─BasicBlock (0)                    [64, 256, 14, 14]    [64, 512, 7, 7]      --                   True\n",
       "│    │    └─Conv2d (conv1)               [64, 256, 14, 14]    [64, 512, 7, 7]      1,179,648            True\n",
       "│    │    └─BatchNorm2d (bn1)            [64, 512, 7, 7]      [64, 512, 7, 7]      1,024                True\n",
       "│    │    └─ReLU (act1)                  [64, 512, 7, 7]      [64, 512, 7, 7]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [64, 512, 7, 7]      [64, 512, 7, 7]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn2)            [64, 512, 7, 7]      [64, 512, 7, 7]      1,024                True\n",
       "│    │    └─Sequential (downsample)      [64, 256, 14, 14]    [64, 512, 7, 7]      132,096              True\n",
       "│    │    └─ReLU (act2)                  [64, 512, 7, 7]      [64, 512, 7, 7]      --                   --\n",
       "│    └─BasicBlock (1)                    [64, 512, 7, 7]      [64, 512, 7, 7]      --                   True\n",
       "│    │    └─Conv2d (conv1)               [64, 512, 7, 7]      [64, 512, 7, 7]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn1)            [64, 512, 7, 7]      [64, 512, 7, 7]      1,024                True\n",
       "│    │    └─ReLU (act1)                  [64, 512, 7, 7]      [64, 512, 7, 7]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [64, 512, 7, 7]      [64, 512, 7, 7]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn2)            [64, 512, 7, 7]      [64, 512, 7, 7]      1,024                True\n",
       "│    │    └─ReLU (act2)                  [64, 512, 7, 7]      [64, 512, 7, 7]      --                   --\n",
       "├─SelectAdaptivePool2d (global_pool)     [64, 512, 7, 7]      [64, 512]            --                   --\n",
       "│    └─AdaptiveAvgPool2d (pool)          [64, 512, 7, 7]      [64, 512, 1, 1]      --                   --\n",
       "│    └─Flatten (flatten)                 [64, 512, 1, 1]      [64, 512]            --                   --\n",
       "├─Linear (fc)                            [64, 512]            [64, 1]              513                  True\n",
       "========================================================================================================================\n",
       "Total params: 11,189,569\n",
       "Trainable params: 11,189,569\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 126.14\n",
       "========================================================================================================================\n",
       "Input size (MB): 89.92\n",
       "Forward/backward pass size (MB): 2543.32\n",
       "Params size (MB): 44.76\n",
       "Estimated Total Size (MB): 2678.00\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRANSFER LEARNING SCENARIO\n",
    "base_model = torchgeo.models.resnet18(weights=torchgeo.models.ResNet18_Weights.SENTINEL2_ALL_MOCO)\n",
    "model = build_from_config( base_model=base_model, config_file=CONFIG_FILE )\n",
    "torchinfo.summary(\n",
    "    model, \n",
    "    input_size=(int(config['batch_size']), 7, 224, 224), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n",
    "    verbose=0,\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "302b314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE LOSS, OPTIM\n",
    "loss_fn = utils.configure_loss( config )\n",
    "optimizer = utils.configure_optimizer( config, model )\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "r2 = torchmetrics.R2Score()\n",
    "r2 = r2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6455c783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "results = train(\n",
    "    model=model,\n",
    "    train_dataloader=val_loader,\n",
    "    val_dataloader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=config['n_epochs'],\n",
    "    batch_size=config['batch_size'],\n",
    "    in_channels=config['in_channels'],\n",
    "    metric=r2,\n",
    "    writer=writer,\n",
    "    device=device\n",
    ")\n",
    "torch.save(model.state_dict(), config['checkpoint_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa0c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(config['checkpoint_path']))\n",
    "# model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccb8ae5a",
   "metadata": {},
   "source": [
    "3. Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db74dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_r2, Y_true, Y_pred = test(model=model, dataloader=test_loader, metric=r2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dfbb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.regplot(x=Y_true, y=Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d7d711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
